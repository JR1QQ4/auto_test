# 软件测试

> 极客时间，软件测试52讲，茹炳晟

## 测试基础知识篇

### 01 你真的懂测试吗？从“用户登录”测试谈起

作为测试工程师，你的目标是要保证系统在各种应用场景下的功能使符合设计要求的，所以你需要考虑的测试用例就需要更多、更全面

三个个最常用、最典型的黑盒测试方法:

- 等价类划分方法，是将所有可能的输入数据划分成若干个子集，在每个子集中，如果任意一个输入数据对于揭露程序中潜在错误都具有同等效果，
那么这样的子集就构成了一个等价类。后续只要从每个等价类中任意选取一个值进行测试，就可以用少量具有代表性的测试输入取得较好的测试覆盖
结果
- 边界值分析方法，是选取输入、输出的边界值进行测试。因为通常大量的软件错误是发生在输入或输出范围的边界上，所以需要对边界值进行重点
测试，通常选取正好等于、刚刚大于或刚刚小于边界的值作为测试数据。边界值分析是对等价类划分的补充
- 错误推测方法，是指基于对被测试软件系统设计的理解、过往经验以及个人直觉，推测出软件可能存在的缺陷，从而由针对性的设计测试用例的
方法。这个方法强调的是对被测软件的需求理解以及设计实现的细节把握，当然还有个人的能力

一个质量过硬的软件系统，除了显式功能性需求以外，其他的非功能性需求，即隐式功能性需求（安全性、性能以及兼容性）也是极其关键的

在绝大多数的软件工程实践中，测试由于受限于时间成本和经济成本，是不可能去穷尽所有可能的组合的，而是采用基于风险驱动的模式，有所侧重
地选择测试范围和设计测试用例，以寻求缺陷风险和研发成本之间的平衡

### 如何设计一个“好的”测试用例？

好的测试用例一定是一个完备的集合，它能够覆盖所有等价类以及各种边界值，而根能否发现缺陷无关。好的测试用例必须具备以下三个特征:

- 整体完备性: 好的测试用例一定是一个完备的整体，是有效测试用例组成的集合，能够完全覆盖测试需求
- 等价类划分的准确性: 指的是对于每个等价类都能保证只要其中一个输入测试通过，其他输入也一定测试通过
- 等价类集合的完备性: 需要保证所有可能的边界值和边界条件都已经正确识别

对大多数的软件测试者，综合使用等价类划分、边界值分析和错误推测者三大类方法就足够了

在具体的用例设计时，首先需要搞清楚每一个业务需求所对应的多个软件功能需求点，然后分析出每个软件功能需求点对应的多个测试需求点，最后
再针对每个测试需求点设计测试用例

### 什么是单元测试？如何做好单元测试？

单元测试是指，对软件中的最小可测试单元在与程序其他部分相隔离的情况下进项检查和验证的工作，这里的最小可测试单元通常是指函数或者类

要做好单元测试，你首先必须弄清除单元测试的对象是代码，以及代码的基本特征和产生错误的原因，然后你必须掌握单元测试的基本方法和主要
技术手段，比如什么是驱动代码、桩代码和 Mock 代码等:

- 第一，代码的基本特征与产生错误的原因：
    - 如果要实现正确的功能逻辑，会有哪几种正常的输入
    - 是否由需要特殊处理的多种边界输入
    - 各种潜在非法输入的可能性以及如何处理
- 第二，单元测试用例详解
    - 输入数据种类: 
        - 被测试函数的输入参数
        - 被测试函数内部需要读取的全局静态变量
        - 被测试函数内部需要读取的成员变量
        - 函数内部调用子函数获得的数据
        - 函数内部调用子函数改写的数据
        - 嵌入式系统中，在中断调用时改写的数据
    - 预计输出的分类:
        - 被测试函数的返回值
        - 被测试函数的输出参数
        - 被测试函数所改写的成员变量
        - 被测试函数所改写的全局变量
        - 被测试函数中进行的文件更新
        - 被测试函数中进行的数据库更新
        - 被测试函数中尽心过的消息队列更新
- 第三，驱动代码，桩代码和 Mock 代码
    - 驱动代码（Driver）指调用被测函数的代码，在单元测试过程中，驱动模块通常包括调用北侧函数前的数据准备、调用被测函数以及验证相关
    结果三个步骤。驱动代码的结构，通常由单元测试的框架决定
    - 桩代码（Stub）是用来代替真实代码的临时代码。比如，某个函数 A 的内部实现中调用了一个尚未实现的函数 B，为了对函数 A 的逻辑进行
    测试，那么就需要模拟一个函数 B，这个模拟的函数 B 的实现就是所谓的桩代码
        - 编写桩代码通常需要遵守以下三个原则:
            - 桩函数要具有与原函数完全相同的原形，仅仅是内部实现不同，这样测试代码才能正确链接到桩函数
            - 用于实现隔离和补充的桩函数比较简单，只需保持原函数的声明，加一个空的实现，目的是通过编译链接
            - 实现控制功能的桩函数是应用最广泛的，要根据测试用例的需要，输出何时的数据作为被测函数的内部输入
    - Mock 代码和桩代码非常类似，都是用来替代真实代码的临时代码，起到隔离和补齐的作用。Mock 代码和桩代码的本质区别是: 测试期待
    结果的验证（Assert and Expectation）
        - 对于 Mock 代码来说，关注点是 Mock 方法有没有被调用，以什么样的参数被调用，被调用的次数，以及多个 Mock 函数的先后调用
        顺序。所以，在使用 Mock 代码的测试中，对于结果的验证（也就是 assert），通常出现在 Mock 函数中
        - 对于桩代码来说，关注点是利用 Stub 来控制被测函数的执行路径，不会去关注 Stub 是否被调用以及怎么样被调用。所以，在使用
        Stub 的测试中，对于结果的验证（也就是 assert），通常出现在驱动代码中
        
### 为什么要做自动化测试？什么样的项目适合做自动化测试？

自动化测试是，把人对软件的测试行为转化为由机器执行测试行为的一种实践，对于最常见的 GUI 自动化测试来讲，就是由自动化测试工具模拟之前
需要人工在软件界面上的各种操作，并且自动验证其结果是否符合预期

当你发现自动化测试用例的维护成本高于其节省的测试成本时，自动化测试就失去了价值与意义，你也就需要在是否使用自动化测试上权衡取舍了

适合自动化测试的项目:

- 第一，需求稳定，不会频繁变更
- 第二，研发和维护周期唱，需要频繁执行回归测试
    - 对于一些中长期项目，对比较稳定的软件功能进行自动化测试，对变动较大或者需求暂时不明确的功能进行手工测试，最终目标是用 20% 的
    精力去覆盖 80% 的回归测试
- 第三，需要在多种平台上反复运行相同测试的场景
- 第四，某些测试项目通过手工测试无法实现，或者手工测试成本太高
- 第五，被测软件的开发较为规范，能够保证系统的可测试性
- 第六，测试人员已经具备一定的编程能力

### 你知道软件开发各阶段都有哪些自动化测试技术吗？

单元测试阶段的自动化不仅仅指测试用例执行的自动化，还应该包含以下五个方面:

1. 用例框架代码生成的自动化
2. 部分测试输入数据的自动化生成
3. 自动桩代码的生成
    - 抽桩，在单元测试阶段，假如函数 A 内部调用的函数 B 是桩代码，那么在代码级集成测试阶段，我们希望函数 A 不再调用假的函数 B，
    而是调用真实的函数 B，这个用真实函数 B 代替原本桩代码函数 B 的操作，就称为 “插桩” 
4. 被测代码的自动化静态分析
5. 测试覆盖率的自动统计与分析

代码级集成测试，是指将已经开发完成的软件模块放在一起测试:

- 代码级集成测试与单元测试最大的区别只是，代码级集成测试中被测函数内部调用的其他函数必须是真实的，不允许使用桩代码代替，而
单元测试中允许使用桩代码来模拟内部调用的其他函数

Web Service 测试的自动化技术，主要是指 SOAP API 和 REST API 这两类 API 测试，最典型的是采用 SoapUI 或 Postman 等类似的工具。但
这类测试工具基本都是界面操作手动发起 Request 并验证 Response，所以难以和 CI/CD 集成，于是就出现了 API 自动化测试框架

Web Service 测试自动化不仅仅包括 API 测试用例执行的自动化，还包括以下四个方面:

1. 测试脚手架代码的自动化生成
2. 部分测试输入数据的自动生成
3. Response 验证的自动化
4. 基于 SoapUI 或者 Postman 的自动化脚本生成

GUI 测试的自动化技术，目前主要分为两个方向，传统 Web 浏览器和移动端原生应用（Native App）的 GUI 自动化。虽然二者采用的具体技术
差别很大，但是用例设计的思路类似:

- 对于传统 Web 浏览器的 GUI 自动化测试，业内主要的开源方案采用 Selenium，商业方案采用 Micro Focus 的 UFT（前身是 HP 的 QTP）
- 对于移动端原生应用，通常采用主流的 Appium，它对 iOS 环境集成了 XCUITest，对 Android 环境集成了 UIAutomator 和 Espresso

### 你真的懂测试覆盖率吗？

测试覆盖率通常被用来衡量测试的充分性和完整性，从广义的角度来讲，测试覆盖率主要分为两大类，一类是面向项目的需求覆盖率，另一类是更
偏向技术的代码覆盖率。现在人们口中的测试覆盖率，通常默认指代码覆盖率，而不是需求覆盖率

三种代码覆盖率指标:

- 行覆盖率又称为语句覆盖率，指已经执行到的语句占总可执行语句的百分比，实际项目中通常会结合判定覆盖率或者条件覆盖率一起使用
- 判定覆盖率又称分支覆盖率，用以度量程序中每一个判定的分支是否都被测试到了，即代码中每个判断的取真分支和取假分支是否各被覆盖
至少各一次。比如，if(a>0 && b>0)，就要求覆盖 “a>0 && b>0” 为 TRUE 和 FALSE 各一次
- 条件覆盖是指，叛党中每个条件的可能取值至少满足一次，度量判定中的每个条件的结果 TRUE 和 FALSE 是否都被测试到了。
比如，if(a>0 && b>0)，就要求 “a>0” 取 TRUE 和 FALSE 各一次，同时要求 “b>0” 取 TRUE 和 FALSE 各一次

统计代码覆盖率的根本目的是找出潜在的遗漏测试用例，并由针对性的进行补充，同时还可以识别代码中那些由于需求变更等原因造成的不可达的
废弃代码
 
总结来讲，高的代码覆盖率不一定能保证软件的质量，但是低的代码覆盖率一定不能保证如软件的质量
 
实现代码覆盖率的统计，最基本的方法就是注入（instrumentation）。简单地说，注入就是在被测代码中自动插入用于覆盖率统计地
探针（Probe）代码，并保证插入的探针代码不会给原代码带来任何影响

### 如何高效填写软件缺陷报告？

缺陷报告本身的质量将直接关系到缺陷被修复的速度以及开发工程师的效率，同时还会影响测试工程师的信用、测试与开发人员协作的有效性:

- 缺陷标题通常是别人最先看到的部分，是对缺陷的概括性描述，通常采用 “在什么情况下发生了什么问题” 的模式
- 缺陷概述通常会提供更多概括性的缺陷本质与现象的描述
- 缺陷影响
- 环境配置
- 前置条件
- 缺陷重现步骤是整个缺陷报告中最核心的内容，其目的在于用简洁的语言向开发工程师展示缺陷重现的具体操作步骤
- 期望结果和实际结果
- 优先级（Priority）和严重程度（Severity）
    - 严重程度是缺陷本身的属性，通常确定后不再变化，事情的紧急程度
    - 优先级是缺陷的工程属性，会随着项目进度、解决缺陷的成本等因素而变动，事情的重要程度
- 变通方案（Workaround）
- 根原因分析（Root Cause Analysis）
- 附件（Attachment）

### 以终为始，如何才能做好测试计划？

一份好的测试计划要包括: 测试范围、测试策略、测试资源、测试进度和测试风险评估:

- 测试范围需要明确 “测什么” 和 “不测什么”
- 测试策略需要明确 “先测什么后测什么” 和 “如何来测”
- 测试资源需要明确 “谁来测” 和 “在哪里测”
- 测试进度需要明确各类测试的开始时间，所需工作量和预计完成时间
- 测试风险评估是需要明确如何有效应对各种潜在的变化

### 软件测试工程师的核心竞争力是什么？

把测试工程师按照工作内容，分为了功能测试工程师（即传统测试工程师）和测试开发工程师两类:

- 功能测试工程师，其核心竞争力包括: 测试策略设计能力、测试用例设计能力、快速学习能力、探索性测试思维、缺陷分析能力、自动化测试技术
和良好的沟通能力
- 测试开发工程师，需要具备优秀的测试系统需求分析能力和完备的知识体系

### 软件测试工程师需要掌握的非测试知识由哪些？

软件测试工程师需要掌握非常多的非测试专业知识，包括: 网站架构、容器技术、云计算技术、DevOps思维，以及前端开发技术的核心知识以及实践

### 互联网产品的测试策略应该如何设计？

发布周期的巨大差异决定了，传统软件产品的测试策略必然不适用于互联网产品的测试，二者的测试必然在测试执行实践和测试执行环境上由巨大差异

传统软件产品的测试策略，通常采用迈克·科恩（Mike Cohn）提出的金字塔模型，从下网上依次是: 单元测试、API 测试、GUI 测试，测试数量依次
减少

互联网产品的测试策略，往往采用菱形模型，菱形模型有以下四个关键点:

- 以中间层的 API 测试为重点做全面的测试
- 轻量级的 GUI 测试，只覆盖最核心直接影响主营业务流程的 E2E 场景
- 最上层的 GUI 测试通常利用探索性测试思维，以人工测试的方式发现尽可能多的潜在问题
- 单元测试采用 “分而治之” 的思想，只对那些相对稳定并且核心的服务和模块开展全面的单元测试，而应用层或者上层业务只会做少量的单元测试

## GUI自动化测试篇

### 从0到1：你的第一个GUI自动化测试

Selenium 1.0，又称 Selenium RC，其中 RC 是 Remote Control 的缩写。Selenium RC 利用的原理是：JavaScript 代码可以很方便地获取
页面上的任何元素并执行各种操作

但是因为 " 同源政策（Same-origin policy）"（只有来自相同域名、端口和协议的 JavaScript 代码才能被浏览器执行），所以要想在测试用例
运行中的浏览器中，注入 JavaScript 代码从而实现自动化的 Web 操作，Selenium RC 就必须“欺骗”被测站点，让它误以为被注入的代码是同源的

Selenium 2.0，又称 Selenium WebDriver，它利用的原理是：使用浏览器原生的 WebDriver 实现页面操作。它的实现方式完全不同于 
Selenium 1.0。Selenium WebDriver 是典型的 Server-Client 模式，Server 端就是 Remote Server

### 效率为王：脚本与数据的解耦 + Page Object模型

“测试脚本和数据解耦”的本质是实现了数据驱动的测试，让操作相同但是数据不同的测试可以通过同一套自动化测试脚本来实现，只是在每次测试
执行时提供不同的测试输入数据

页面对象模型的核心理念是，以页面（Web Page 或者 Native App Page）为单位来封装页面上的控件以及控件的部分操作。而测试用例，更确切地
说是操作函数，基于页面封装对象来完成具体的界面操作，最典型的模式是“XXXPage.YYYComponent.ZZZOperation”

### 更接近业务的抽象：让自动化测试脚本更好地描述业务

操作函数的粒度是指，一个操作函数到底应该包含多少操作步骤才是最合适的:

- 如果粒度太大，就会降低操作函数的可重用性。极端的例子就是，百度搜索的案例，把 “登录” “搜索” “登出” 的操作作为一个操作函数
- 如果粒度太小，也就失去了操作函数封装的意义。极端的例子就是，把每一个步骤都作为一个操作函数
- 更糟糕的是，在企业实际自动化测试开发中，每个测试工程师对操作函数的粒度理解也不完全相同，很有可能出现同一个项目中脚本粒度差异过大，
以及某些操作函数的可重用性低的问题

业务流程抽象是，基于操作函数的更接近于实际业务的更高层次的抽象方式。基于业务流程抽象实现的测试用例往往具有较好的灵活性，可以根据
实际测试需求方便地组装出各种测试用例。

业务流程的核心思想是，从业务的维度来指导测试业务流程的封装。由于业务流程封装通常很贴近实际业务，所以特别适用于组装面向终端用户的
端到端（E2E）的系统功能测试用例，尤其适用于业务功能非常多，并且存在各种组合的 E2E 测试场景。

### 过不了的坎：聊聊GUI自动化过程中的测试数据

GUI 测试中两种常见的数据类型:

- 第一大类是，测试输入数据，也就是 GUI 测试过程中，通过界面输入的数据。比如“用户登录”测试中输入的用户名和密码就就属于这一类数据
- 第二大类是，为了完成 GUI 测试而需要准备的测试数据。比如“用户登录”测试中，需要事先准备好用户账户，以便进行用户的登录测试

从创建的技术手段上来讲，创建测试数据的方法主要分为三种:

1. API 调用
2. 数据库操作
3. 综合运用 API 调用和数据库操作

从创建的时机来讲，创建测试数据的方法主要分为两种:

1. 测试用例执行过程中，实时创建测试数据，我们通常称这种方式为 On-the-fly
2. 测试用例执行前，事先创建好 “开箱即用” 的测试数据，我们通常称这种方式为 Out-of-box

在实际项目中，对于创建数据的技术手段而言，最佳的选择是利用 API 来创建数据，只有当 API 不能满足数据创建的需求时，才会使用数据库操作
的手段

实际上，往往很多测试数据的创建是基于 API 和数据库操作两者的结合来完成，即先通过 API 创建基本的数据，然后调用数据库操作来修改数据，
以达到对测试数据的特定要求

而对于创建数据的时机，在实际项目中，往往是 On-the-fly 和 Out-of-box 结合在一起使用

对于相对稳定的测试数据，比如商品类型、图书类型等，往往采用 Out-of-box 的方式以提高效率；而对于那些只能一次性使用的测试数据，比如
商品、订单、优惠券等，往往采用 On-the-fly 的方式以保证不存在脏数据问题

### 脑洞大开：GUI测试还能这么玩（Page Code Gen + Data Gen + Headless）？

Page Object模型伪代码:

```
Class loginPage{
    username_input = findElementByName("username");
    password_input = findElementByName("password");
    login_ok_button = findElementByName("login_ok_button");
    login_cancel_button = findElementByName("login_cancel_button")
}
login(username, password){
    loginPage.username_input.input(username);
    loginPage.password_input.input(password);
    loginPage.login_ok_button.click();
}
```

如果你在实际项目中已经用过页面对象模型，你会发现开发和维护页面对象的类（Page Class），是一件很耗费时间和体力的事儿

页面对象自动生成技术，属于典型的 “自动化你的自动化” 的应用场景。它的基本思路是，你不用再手工维护 Page Class 了，只需要提供 Web 的
URL，它就会自动帮你生成这个页面上所有控件的定位信息，并自动生成 Page Class。

GUI 测试数据自动生成，指的由机器自动生成测试用例的输入数据。仅仅局限于以下两种情况:

1. 根据 GUI 输入数据类型，以及对应的自定义规则库自动生成测试输入数据。 比如，GUI 界面上有一个“书名”输入框，它的数据类型是 string。
那么，基于数据类型就可以自动生成诸如 Null、SQL 注入、超长字符串、非英语字符等测试数据。
2. 对于需要组合多个测试输入数据的场景，测试数据自动生成可以自动完成多个测试数据的笛卡尔积组合，然后再以人工的方式剔除掉非法的数据
组合。但是，这种方式并不一定是最高效的。
    - 更常见的用法是，先手动选择部分输入数据进行笛卡尔积，并删除不合法的部分；然后，在此基础上，
再人为添加更多业务上有意义的输入数据组合。
        - 比如，输入数据有 A、B、C、D、E、F 六个参数，你可以先选取最典型的几个参数生成笛卡尔积，假设这里选取 A、B 和 C；
        - 然后，在生成的笛卡尔积中删除业务上不合法的组合；
        - 最后，再结合 D、E 和 F 的一些典型取值，构成更多的测试输入数据组合

无头浏览器，即 Headless Browser，是一种没有界面的浏览器。

- 其实是一个特殊的浏览器，你可以把它简单地想象成是运行在内存中的浏览器。它拥有完整的浏览器内核，包括 JavaScript 解析引擎、渲染
引擎等。
- 与普通浏览器最大的不同是，无头浏览器执行过程中看不到运行的界面，但是你依然可以用 GUI 测试框架的截图功能截取它执行中的页面。

无头浏览器、页面对象自动生成，以及 GUI 测试数据自动生成:

- 对于页面对象自动生成，商用测试软件已经实现了这个功能。但是，如果你选择开源测试框架，就需要自己实现这个功能了
- GUI 测试数据自动生成，主要是基于测试输入数据的类型以及对应的自定义规则库实现的，并且对于多个测试输入数据，可以基于笛卡尔积来自动
组合出完整的测试用例集合
- 目前，Headless Chrome 结合 Puppeteer 是无头浏览器方案的其中之一

### 精益求精：聊聊提高GUI测试稳定性的关键技术

要提高 GUI 测试稳定性，首先你需要知道到底是什么原因引起的不稳定。你必须找出尽可能多的不稳定因素，然后找到每一类不稳定因素对应的
解决方案。

五种造成 GUI 测试不稳定的因素:

1. 非预计的弹出对话框；
    - 一般包含两种场景：
        - GUI 自动化测试用例执行过程中，操作系统弹出的非预计对话框， 有可能会干扰 GUI 测试的自动化执行
        - 被测软件本身也有可能在非预期的时间弹出预期的对话框， GUI 自动化测试有可能会因此而失败
    - 解决:
        - 当自动化脚本发现控件无法正常定位，或者无法操作时，GUI 自动化框架自动进入 “异常场景恢复模式”
        - 在“异常场景恢复模式”下，GUI 自动化框架依次检查各种可能出现的对话框，一旦确认了对话框的类型，立即执行预定义的操作（比如，
        单击“确定”按钮，关闭这个对话框），接着重试刚才失败的步骤
2. 页面控件属性的细微变化；
    - 采用“组合属性”定位控件会更精准，而且成功率会更高，如果能在此基础上加入“模糊匹配”技术，可以进一步提高控件的识别率
    - “模糊匹配” 是指，通过特定的相似度算法，控件属性发生细微变化时，这个控件依旧可以被准确定位
3. 被测系统的 A/B 测试；
    - A/B 测试，是互联网产品常用的一种测试方法。它为 Web 或 App 的界面或流程提供两个不同的版本，然后让用户随机访问其中一个版本，并
    收集两个版本的用户体验数据和业务数据，最后分析评估出最好的版本用于正式发布
    - 需要在测试用例脚本中做分支处理，并且需要脚本做到正确识别出不同的分支
4. 随机的页面延迟造成控件识别失败；
    - 一个屡试不爽的办法就是，加入重试（retry）机制。重试机制是指，当某一步 GUI 操作失败时，框架会自动发起重试，重试可以是步骤级别
    的，也可以是页面级别的，甚至是业务流程级别的
5.  测试数据问题
    - 构造自动化数据时要特别注意，构造一些带特殊字段的数据库信息，最好是超出常人操作的数据信息，这样可以有效避免数据被误修改的风险

### 眼前一亮：带你玩转GUI自动化的测试报告

早期基于视频的 GUI 测试报告由于体积较大，而且不能比较方便地和日志适配，所以并不是最好的解决方案。

理想中的 GUI 测试报告应该是由一系列按时间顺序排列的屏幕截图组成，并且这些截图上可以高亮显示所操作的元素，同时按照执行顺序配有相关
操作步骤的详细描述。

商业 GUI 自动化测试框架的 GUI 测试报告已经做得非常成熟，通常不需要做额外的定制或者开发。但是开源 GUI 自动化测试框架的 GUI 测试报告
往往需要自己来开发，主要使用了扩展 Selenium 原本的操作函数的方式以及 Hook 函数来实现。

问题步骤记录器 是隐藏在 Windows 里的辅助工具，只需在 开始 > 运行 中输入 psr 就能开启，它能一步一步记录电脑操作流程，方便解决无法
描述之问题

### 真实的战场：如何在大型项目中设计GUI自动化测试策略

首先，要从前端组件的级别来保证质量，也就是需要对那些自定义开发的组件进行完整全面的测试。

- 公共组件库会被很多上层的前端模块依赖，它的质量将直接影响这些上层模块的质量，所以我们往往会对这些公共组件进行严格的单元测试。
- 最常用的方案是：基于 Jest 开展单元测试，并考量 JavaScript 的代码覆盖率指标。
- Jest 是由 Facebook 发布的，是一个基于 Jasmine 的开源 JavaScript 单元测试框架，是目前主流的 JavaScript 单元测试方案。
- 完成单元测试后，往往还会基于被测控件构建专用的测试页面，在页面层面再次验证控件相关的功能和状态。这部分测试工作也需要采用自动化的
形式实现，具体的做法是:
    1. 先构建一个空页面，并加入被测控件，由此可以构建出一个包含被测控件的测试页面，这个页面往往被称为 Dummy Page；
    2. 从黑盒的角度出发，在这个测试页面上通过手工和自动化的方式操作被测控件，并验证其功能的正确性。

其次，每一个前端模块，都会构建自己的页面对象库，并且在此基础上封装开发自己的业务流程脚本。这些业务流程的脚本，可以组装成每个前端模块
的测试用例。

- 以用户管理模块为例，测试用例的组装过程如下:
    - 首先，把用户管理模块中涉及到的所有页面，比如登录页面、用户注册页面等，按照页面对象模型的要求写成 Page 类；
    - 然后，利用这些 Page 类封装业务流程脚本，比如用户登录流程，用户注册流程等；
    - 最后，在 GUI 测试用例脚本中，调用封装好的业务流程脚本构成该模块的 GUI 测试用例。

最后，组合各个前端模块，并站在终端用户的视角，以黑盒的方式使用网站的端到端（E2E）测试。 这部分的测试主要分为两大部分:

- 一部分是，通过探索式测试的方法手工执行测试，目标是尽可能多地发现新问题；
- 另一部分是，通过 GUI 自动化测试执行基本业务功能的回归测试，保证网站核心业务相关的所有功能的正确性。

为了能够在端到端的 GUI 自动化测试中，复用各个模块的页面对象和业务流程脚本，建议的方案是：对各个前端业务模块的页面对象库和业务流程
脚本，实施版本化管理机制

### 与时俱进：浅谈移动应用测试方法与思路

移动应用根据技术架构的不同，主要分为 Web App、Native App 和 Hybrid App 三大类，这三类应用的测试方法本质上都属于 GUI 测试的范畴

从业务功能测试的角度看，移动应用的测试用例设计和传统 PC 端的 GUI 自动化测试策略比较类似，只是测试框架不同，数据驱动、页面对象模型
和业务流程封装依旧适用

各种专项测试是移动应用的测试重点，也有别于传统 GUI 测试。专项测试包括：交叉事件测试、兼容性测试、流量测试、耗电量测试、弱网络测试
和边界测试

- 耗电测试中，Google推出的history batterian工具很好分析耗电情况
- 弱网络测试，推荐一款非常棒的开源移动网络测试工具：Facebook 的 Augmented Traffic Control（ATC）

### 移动测试神器：带你玩转Appium

早期版本和网上很多教程都建议用命令行的形式启动 Appium Server，你完全可以通过界面启动（在 Launchpad 中找到 Appium 的图标，点击即
可启动），而且新版本的 Appium 也推荐这个启动方式。通过界面启动，是目前最简单直接的方式。

然后，你需要用命令行“npm install -g appium-doctor”安装 Appium 的环境诊断工具 appium-doctor，用于检查 Appium 所依赖的相关环境
变量以及其他安装包是否都已经配置好了。如果还没有，就需要逐个安装，并根据 appium-doctor 的提示配置环境变量。

这里，Appium 最主要的依赖项主要有：Java、Node.js、Xcode、Carthage、Android SDK、adb 等。

## API自动化测试篇

### 从0到1：API测试怎么做？常用API测试工具简介

通常来讲，无论采用什么 API 测试工具，API 测试的基本步骤主要包括以下三大步骤:

1. 准备测试数据（这是可选步骤，不一定所有 API 测试都需要这一步）；
2. 通过 API 测试工具，发起对被测 API 的 request；
3. 验证返回结果的 response

对 API 的测试往往是使用 API 测试工具，比如常见的命令行工具 cURL、图形界面工具 Postman 或者 SoapUI、API 性能测试的 JMeter 等

其中，cURL 只具备发起 API 调用的功能，而不具备结果验证能力，所以严格地说它并不属于测试工具的范畴。Postman 常常被用于 
Web Service API 的测试具体的操作，测试流程主要包括：发起 API 调用、添加结果验证、保存测试用例、基于 Postman 的测试代码自动生成

在实际项目中，除了这种单个 API 的测试场景外，还有很多复杂场景的 API 测试:

- 测试场景一：被测业务操作是由多个 API 调用协作完成
    - 解决这个问题的核心思路是，通过网络监控的手段，捕获单个前端操作所触发的 API 调用序列。比如，通过类似于 Fiddler 之类的网络抓包
    工具，获取这个调用序列；又比如，目前很多互联网公司还在考虑基于用户行为日志，通过大数据手段来获取这个序列
- 测试场景二：API 测试过程中的第三方依赖
    - 解决这个问题的核心思路是，启用 Mock Server 来代替真实的 API
- 测试场景三：异步 API 的测试
    - 异步 API 是指，调用后会立即返回，但是实际任务并没有真正完成，而是需要稍后去查询或者回调（Callback）的 API
    - 对异步 API 的测试主要分为两个部分：一是，测试异步调用是否成功，二是，测试异步调用的业务逻辑处理是否正确
        - 异步调用是否成功，这个还比较简单，主要检查返回值和后台工作线程是否被创建两个方面就可以了
        - 但是，对异步调用业务逻辑的测试就比较复杂了，因为异步 API 通常发生在一些比较慢的操作上，比如数据库 I/O、消息队列 I/O 等
            - 此时测试往往需要去验证数据库中的值、消息队列中的值等，这就需要测试代码具有访问和操作数据库或者消息队列的能力
            - 在实际工程项目中，这些能力一般会在测试框架级别提供，也就是说要求 API 测试框架中包含对应的工具类去访问和操作数据库
            或者消息队列等

### 知其然知其所以然：聊聊API自动化测试框架的前世今生

早期的 API 测试，往往都是通过类似 Postman 的工具完成的。但是，由于这类工具都是基于界面操作的，所以有以下两个问题亟待解决:

1. 当需要频繁执行大量的测试用例时，基于界面的 API 测试就显得有些笨拙；
2. 基于界面操作的测试难以与 CI/CD 流水线集成

于是就出现了集成 Postman 和 Newman 的方案，然后再结合 Jenkins 就可以很方便地实现 API 测试与 CI/CDl 流水线的集成。Newman 其实就是
一个命令行工具，可以直接执行 Postman 导出的测试用例

对于需要连续调用多个 API 并且有参数传递的情况，Postman+Newman 似乎就不再是理想的测试方案了

为了解决这个问题，于是就出现了基于代码的 API 测试框架。比较典型的是，基于 Java 的 OkHttP 和 Unirest、
基于 Python 的 http.client 和 Requests、基于 NodeJS 的 Native 和 Request 等

建议的工作模式（Working Model）可以转换成这样：

- 对于 Postman 中已经累积的 Collection，全部由这个工具统一转换成基于代码的 API 测试用例；
- 开发人员继续使用 Postman 执行基本的测试，并将所有测试用例保存成 Collection，后续统一由工具转换成基于代码的 API 测试用例；
- 对于复杂测试场景（比如，顺序调用多个 API 的测试），可以组装由工具转换得到的 API 测试用例代码，完成测试工作

Response 结果发生变化时的自动识别，即使我们没有针对每个 response 字段都去写 assert，仍然可以识别出哪些 response 字段发生了变化

- 具体实现的思路是，在 API 测试框架里引入一个内建数据库，推荐采用非关系型数据库（比如 MongoDB）
- 然后用这个数据库记录每次调用的 request 和 response 的组合，当下次发送相同 request 时
    - API 测试框架就会自动和上次的 response 做差异检测，对于有变化的字段给出告警
- 因为有些字段的值每次 API 调用都是不同的，比如 token 值、session ID、时间戳等，这样每次的调用就都会有告警
    - 解决办法是通过规则配置设立一个“白名单列表”，把那些动态值的字段排除在外

### 紧跟时代步伐：微服务模式下API测试要怎么做？

单体架构（Monolithic Architecture）是早期的架构模式，并且存在了很长时间。单体架构是将所有的业务场景的表示层、业务逻辑层和数据访问
层放在同一个工程中，最终经过编译、打包，并部署在服务器上

- 比如，经典的 J2EE 工程，它就是将表示层的 JSP、业务逻辑层的 Service、Controller 和数据访问层的 DAO（Data Access Objects），打
包成 war 文件，然后部署在 Tomcat、Jetty 或者其他 Servlet 容器中运行

微服务（Microservice Architecture）是一种架构风格。在微服务架构下，一个大型复杂软件系统不再由一个单体组成，而是由一系列相互独立的
微服务组成。其中，各个微服务运行在自己的进程中，开发和部署都没有依赖

- 不同服务之间通过一些轻量级交互机制进行通信，例如 RPC、HTTP 等
- 服务可独立扩展伸缩，每个服务定义了明确的边界，只需要关注并很好地完成一件任务就可以了
- 不同的服务可以根据业务需求实现的便利性而采用不同的编程语言来实现，由独立的团队来维护

为了既能保证 API 质量，又能减少测试用例数量，于是有了基于消费者契约的 API 测试。基于消费者契约的 API 测试的核心思想是：只测试那些
真正被实际使用到的 API 调用，如果没有被使用到的，就不去测试

基于消费者契约的测试方法，由于收集到了完整的契约，所以基于契约的 Mock Service 完美地解决了 API 之间相互依赖耦合的问题

## 代码测试篇

### 不破不立：掌握代码级测试的基本理念与方法

代码级测试这个系列，测试人员应该具备的代码级测试基础知识，包括代码级测试技术入门、方法论、用例设计，以及覆盖率衡量、典型难点、解决
思路

代码级测试的测试方法一定是一套测试方法的集合，而不是一个测试方法。因为单靠一种测试方法不可能发现所有潜在的错误，一定是一种方法解决一
部分或者一类问题，然后综合运用多种方法解决全部问题

代码错误，可以划分为“有特征”的错误和“无特征”的错误两大类。其中，“有特征”的错误，又可以进一步细分为语法特征错误、边界行为特征错误
和经验特征错误；而“无特征”的错误，主要包括算法错误和部分算法错误两类

常见代码错误类型:

- 第一，语法特征错误，从编程语法上就能发现的错误。比如，不符合编程语言语法的语句等
- 第二，边界行为特征错误，代码在执行过程中发生异常，崩溃或者超时。之所以称为“边界”，是由于此类错误通常都是发生在一些边界条件上
- 第三，经验特征错误，根据过往经验发现代码错误
- 第四，算法错误，代码完成的计算（或者功能）和之前预先设计的计算结果（或者功能）不一致
- 第五，部分算法错误，在一些特定的条件或者输入情况下，算法不能准确完成业务要求实现的功能

代码级测试方法主要分为两大类，分别是静态方法和动态方法:

- 静态方法，顾名思义就是在不实际执行代码的基础上发现代码缺陷的方法，又可以进一步细分为人工静态方法和自动静态方法
- 动态方法是指，通过实际执行代码发现代码中潜在缺陷的方法，同样可以进一步细分为人工动态方法和自动动态方法

### 深入浅出之静态测试方法

人工静态方法检查代码错误，主要有代码走查、结对编程，以及同行评审这三种手段。那么我们接下来就看一下这三种方法是如何执行的:

- 代码走查（Code Review），是由开发人员检查自己的代码，尽可能多地发现各类潜在错误
- 结对编程（Pair Programming），是一种敏捷软件开发的方法，一般是由两个开发人员结成对子在一台计算机上共同完成开发任务。
    - 其中，一个开发人员实现代码，通过被称为“驾驶员”；另一个开发人员审查输入的每一行代码，通常被称为“观察员”
    - 当“观察员”对代码有任何疑问时，会立即要求“驾驶员”给出解释。解释过程中，“驾驶员”会意识到问题所在，进而修正代码设计和实现
- 同行评审（Peer Review），是指把代码递交到代码仓库，或者合并代码分支（Branch）到主干（Master）前
    - 需要和你同技术级别或者更高技术级别的一个或多个同事对你的代码进行评审，只有通过所有评审后，你的代码才会被真正递交

自动静态方法，因为自动化程度高、成本低、发现的代码问题广等特点，是常用的代码级测试方法。

- 测试工程师需要完成代码静态扫描环境的搭建，使用 Sonar
    - 可以在 IDE 中引入 SonarLint 插件。你可以通过 IDE 的 plugin（插件）管理界面安装 SonarLint
    - 另外，在 IDE 中绑定 SonarQube，就可以把 SonarLint 和 SonarQube（搭建的 Sonar 服务器） 集成在一起了
- 目前，自动静态扫描通常都会和持续集成的流水线做绑定，最常见的应用场景是当你递交代码后，持续集成流水线就会自动触发自动静态扫描
    - 这一功能是通过 Jenkins 以及 Jenkins 上的 SonarQube 插件来完成的，当你在 Jenkins 中安装了 SonarQube Plugin
    - 并且将 SonarQube 服务器相关的配置信息加入 Plugin 之后，你就可以在 Jenkins Job 的配置中增加 Sonar 静态扫描步骤了

### 深入浅出之动态测试方法

单元测试中三个最主要的难点:

1. 单元测试用例“输入参数”的复杂性；输入参数的分类:
    - 第一，被测试函数的输入参数
    - 第二，被测试函数内部需要读取的全局静态变量
    - 第三，被测试函数内部需要读取的类成员变量
    - 第四，函数内部调用子函数获得的数据
    - 第五，函数内部调用子函数改写的数据
    - 第六，嵌入式系统中，在中断调用中改写的数据
2. 单元测试用例“预期输出”的复杂性；预期输出分类:
    - 第一，被测函数的返回值
    - 第二，被测函数的输出参数
    - 第三，被测函数所改写的成员变量和全局变量
3. 关联依赖的代码不可用

自动动态方法，需要重点讨论的是：如何实现边界测试用例的自动生成。解决这个问题最简单直接的方法是，根据被测函数的输入参数生成可能的边界
值

## 性能测试篇

### 带你一起解读不同视角的软件性能与性能指标

对于不同类型的系统，软件性能的关注点各不相同，比如:

- Web 类应用和手机端应用，一般以终端用户感受到的端到端的响应时间来描述系统的性能；
- 非交互式的应用，比如典型的电信和银行后台处理系统，响应时间关注更多的是事件处理的速度，以及单位时间的事件吞吐量

在软件设计开发人员眼中，软件性能通常会包含算法设计、架构设计、性能最佳实践、数据库相关、软件性能的可测试性这五大方面:

- 第一，算法设计包含的点：
    - 核心算法的设计与实现是否高效；
    - 必要时，设计上是否采用 buffer 机制以提高性能，降低 I/O；
    - 是否存在潜在的内存泄露；
    - 是否存在并发环境下的线程安全问题；
    - 是否存在不合理的线程同步方式；
    - 是否存在不合理的资源竞争。
- 第二，架构设计包含的内容：
    - 站在整体系统的角度，是否可以方便地进行系统容量和性能扩展；
    - 应用集群的可扩展性是否经过测试和验证；
    - 缓存集群的可扩展性是否经过测试和验证；
    - 数据库的可扩展性是否经过测试和验证。
- 第三，性能最佳实践包含的点：
    - 代码实现是否遵守开发语言的性能最佳实践；
    - 关键代码是否在白盒级别进行性能测试；
    - 是否考虑前端性能的优化；
    - 必要的时候是否采用数据压缩传输；
    - 对于既要压缩又要加密的场景，是否采用先压缩后加密的顺序。
- 第四，数据库相关的点：
    - 数据库表设计是否高效；
    - 是否引入必要的索引；
    - SQL 语句的执行计划是否合理；
    - SQL 语句除了功能是否要考虑性能要求；
    - 数据库是否需要引入读写分离机制；
    - 系统冷启动后，缓存大量不命中的时候，数据库承载的压力是否超负荷
- 第五，软件性能的可测试性包含的点：
    - 是否为性能分析（Profiler）提供必要的接口支持；
    - 是否支持高并发场景下的性能打点；
    - 是否支持全链路的性能分析。

从性能工程的角度看，性能测试工程师关注的是算法设计、架构设计、性能最佳实践、数据库相关、软件性能的可测试性这五大方面

- 一个优秀的性能测试工程师，一般需要具有以下技能：
    - 性能需求的总结和抽象能力；
    - 根据性能测试目标，精准的性能测试场景设计和计算能力；
    - 性能测试场景和性能测试脚本的开发和执行能力；
    - 测试性能报告的分析解读能力；
    - 性能瓶颈的快速排查和定位能力；
    - 性能测试数据的设计和实现能力；
    - 面对互联网产品，全链路压测的设计与执行能力，能够和系统架构师一起处理流量标记、影子数据库等的技术设计能力；
    - 深入理解性能测试工具的内部实现原理，当性能测试工具有限制时，可以进行扩展二次开发
    - 极其宽广的知识面，既要有“面”的知识，比如系统架构、存储架构、网络架构等全局的知识，还要有大量“点”的知识积累，
        - 比如数据库 SQL 语句的执行计划调优、JVM 垃圾回收（GC）机制、多线程常见问题等等

衡量软件性能的三个最常用的指标：并发用户数、响应时间，以及系统吞吐量

- 并发用户数，是性能需求与测试最常用，也是最重要的指标之一。它包含了业务层面和后端服务器层面的两层含义
    - 业务层面的并发用户数，指的是实际使用系统的用户总数。但是，单靠这个指标并不能反映系统实际承载的压力，我们还要结合用户行为模型
    才能得到系统实际承载的压力
    - 后端服务器层面的并发用户数，指的是“同时向服务器发送请求的数量”，直接反映了系统实际承载的压力
        - 获取用户行为模式的方法，主要分为两种：
            - 对于已经上线的系统来说，往往采用系统日志分析法获取用户行为统计和峰值并发量等重要信息
            - 而对于未上线的全新系统来说，通常的做法是参考行业中类似系统的统计信息来建模，然后分析
- 响应时间，反映了完成某个操作所需要的时间，其标准定义是“应用系统从请求发出开始，到客户端接收到最后一个字节数据所消耗的时间”，是用户
视角软件性能的主要体现
    - 响应时间，分为前端展现时间和系统响应时间两部分
        - 前端时间，又称呈现时间，取决于客户端收到服务器返回的数据后渲染页面所消耗的时间
        - 系统响应时间，又可以进一步划分为 Web 服务器时间、应用服务器时间、数据库时间，以及各服务器间通信的网络时间
    - 严格来讲，响应时间应该包含两层含义：技术层面的标准定义和基于用户主观感受时间的定义
- 系统吞吐量，是最能直接体现软件系统负载承受能力的指标
    - 以不同方式表达的吞吐量可以说明不同层次的问题。比如：
        - “Bytes/Second” 和 “Pages/Second” 表示的吞吐量，主要受网络设置、服务器架构、应用服务器制约；
        - “Requests/Second” 表示的吞吐量，主要受应用服务器和应用本身实现的制约
        
### 聊聊性能测试的基本方法与应用领域

当系统并发用户数较少时，系统的吞吐量也低，系统处于空闲状态，我们往往把这个阶段称为 “空闲区间”

当系统整体负载并不是很大时，随着系统并发用户数的增长，系统的吞吐量也会随之呈线性增长，我们往往把这个阶段称为 “线性增长区间”

随着系统并发用户数的进一步增长，系统的处理能力逐渐趋于饱和，因此每个用户的响应时间会逐渐变长。相应地，系统的整体吞吐量并不会随着并发
用户数的增长而继续呈线性增长。我们往往把这个阶段称为系统的“拐点”

随着系统并发用户数的增长，系统处理能力达到过饱和状态。此时，如果继续增加并发用户数，最终所有用户的响应时间会变得无限长。相应地，系统
的整体吞吐量会降为零，系统处于被压垮的状态。我们往往把这个阶段称为“过饱和区间”

常用的七种性能测试方法:

- 第一，后端性能测试（Back-end Performance Test），即服务器端性能测试
    - 后端性能测试，是通过性能测试工具模拟大量的并发用户请求，然后获取系统性能的各项指标，并且验证各项指标是否符合预期的性能需求的
    测试手段
    - 这里的性能指标，除了包括并发用户数、响应时间和系统吞吐量外，还应该包括各类资源的使用率
        - 比如系统级别的 CPU 占用率、内存使用率、磁盘 I/O 和网络 I/O 等，再比如应用级别以及 JVM 级别的各类资源使用率指标等
- 第二，前端性能测试（Front-end Performance Test）
    - 前端性能关注的是浏览器端的页面渲染时间、资源加载顺序、请求数量、前端缓存使用情况、资源压缩等内容
    - 业界普遍采用的前端测试方法，是雅虎（Yahoo）前端团队总结的 7 大类 35 条前端优化规则
        - 减少 http 请求次数
        - 减少 DNS 查询次数
        - 避免页面跳转
        - 使用内容分发网络（CDN）
        - Gzip 压缩传输文件
- 第三，代码级性能测试（Code-level Performance Test）
    - 代码级性能测试，是指在单元测试阶段就对代码的时间性能和空间性能进行必要的测试和评估，以防止底层代码的效率问题在项目后期才被发
    现的尴尬
    - 最常使用的改造方法是：
        1. 将原本只会执行一次的单元测试用例连续执行 n 次，这个 n 的取值范围通常是 2000~5000；
        2. 统计执行 n 次的平均时间。如果这个平均时间比较长（也就是单次函数调用时间比较长）的话，比如已经达到了秒级，那么通常情况下
        这个被测函数的实现逻辑一定需要优化
- 第四，压力测试（Load/Stress Test），通常指的是后端压力测试
    - 一般采用后端性能测试的方法，不断对系统施加压力，并验证系统化处于或长期处于临界饱和阶段的稳定性以及性能指标
    - 并试图找到系统处于临界状态时的主要瓶颈点。所以，压力测试往往被用于系统容量规划的测试
- 第五，配置测试（Configuration Test）
    - 主要用于观察系统在不同配置下的性能表现，通常使用后端性能测试的方法：
        1. 通过性能基准测试（Performance Benchmark）建立性能基线（Performance Baseline）
        2. 在此基础上，调整配置
        3. 基于同样的性能基准测试，观察不同配置条件下系统性能的差异，根本目的是要找到特定压力模式下的最佳配置
    - “配置”是一个广义配置的概念，包含了以下多个层面的配置：宿主操作系统的、应用服务器的、数据库的、JVM 的、网络环境的...
- 第六，并发测试（Concurrence Test）
    - 指的是在同一时间，同时调用后端服务，期间观察被调用服务在并发情况下的行为表现，旨在发现诸如资源竞争、资源死锁之类的问题
- 第七，可靠性测试（Reliability Test）
    - 验证系统在常规负载模式下长期运行的稳定性
    - 其本质就是通过长时间模拟真实的系统负载来发现系统潜在的内存泄漏、链接池回收等问题

性能测试的四大应用领域: 

- 第一，能力验证
    - 验证“某系统能否在 A 条件下具有 B 能力”，通常要求在明确的软硬件环境下，根据明确的系统性能需求设计测试方案和用例
    - 能力验证这个领域最常使用的测试方法，包括后端性能测试、压力测试和可靠性测试
- 第二，能力规划
    - 能力规划关注的是，如何才能使系统达到要求的性能和容量。通常情况下，我们会采用探索性测试的方式来了解系统的能力
    - 能力规划最常使用的测试方法，主要有后端性能测试、压力测试、配置测试和可靠性测试
- 第三，性能调优
    - 其实是性能测试的延伸
    - 性能调优主要解决性能测试过程中发现的性能瓶颈的问题，通常会涉及多个层面的调整
        - 包括硬件设备选型、操作系统配置、应用系统配置、数据库配置和应用代码实现的优化等等
- 第四，缺陷发现
    - 是一个比较直接的应用领域，通过性能测试的各种方法来发现诸如内存泄露、资源竞争、不合理的线程锁和死锁等问题
    - 最常用的测试方法主要有并发测试、压力测试、后端性能测试和代码级性能测试

### 工欲善其事必先利其器：后端性能测试工具原理与行业常用工具简介

后端性能测试工具主要在性能测试脚本开发、性能场景实现、性能测试执行这三个步骤中发挥作用，而其他环节都要依靠性能测试工程师的专业知识
完成

虽然后端性能测试工具和 GUI 自动化测试工具都是通过自动化的手段模拟终端用户使用系统的行为，但是两者实现的原理截然不同:

- 第一个显著区别是，模拟用户行为的方式
- 第二个显著的区别是，测试的执行方式
    - GUI 自动化测试的执行，一般是单用户执行并验证功能结果
    - 性能测试的执行，往往需要同时模拟大量的并发用户，不仅需要验证业务功能是否成功完成，还要收集各种性能监控指标

后端性能测试工具的原理:

- 首先，后端性能测试工具会基于客户端与服务器端的通信协议，构建模拟业务操作的虚拟用户脚本
- 然后，开发完成了虚拟用户脚本之后，后端性能测试工具会以多线程或多进程的方式并发执行虚拟用户脚本，来模拟大量并发用户的同时访问，
从而对服务器施加测试负载
- 接着，在施加测试负载的整个过程中，后端性能测试工具除了需要监控和收集被测系统的各种性能数据以外，还需要监控被测系统各个服务器的各种
软硬件资源
- 最后，测试执行完成后，后端性能测试工具会将系统监控器收集的所有信息汇总为完整测试报告，后端性能测试工具通常能够基于该报告生成各类
指标的各种图表，还能将多个指标关联在一起进行综合分析来找出各个指标之间的关联性。我们把完成这部分工作的模块称为测试结果分析器

性能测试场景设计，目的是要描述性能测试过程中所有与测试负载以及监控相关的内容。性能测试场景设计主要会涉及以下部分:

- 并发用户数是多少？
- 测试刚开始时，以什么样的速率来添加并发用户？比如，每秒增加 5 个并发用户
- 达到最大并发用户数后持续多长时间？
- 测试结束时，以什么样的速率来减少并发用户？比如，每秒减少 5 个并发用户
- 需要包含哪些业务操作，各个业务操作的占比是多少？比如，10% 的用户在做登录操作，70% 的用户在做查询操作，其他 20% 的用户在做订单操作
- 一轮虚拟用户脚本执行结束后，需要等待多长时间开始下一次执行？
- 同一虚拟用户脚本中，各个操作之间的等待时间是多少？
- 需要监控哪些被测服务器的哪些指标？
- 脚本出错时的处理方式是什么？比如，错误率达到 10% 时，自动停止该脚本
- 需要使用多少台压力产生器？

业内有很多成熟的后端性能测试工具，比如传统的 LoadRunner、JMeter、NeoLoad等。另外，现在还有很多云端部署的后端性能测试工具或平台，
比如 CloudTest、Loadstorm、阿里的 PTS 等

### 工欲善其事必先利其器：前端性能测试工具原理与行业常用工具简介

WebPagetest，是前端性能测试的利器:

- 可以为我们提供全方位的量化指标，包括页面的加载时间、首字节时间、渲染开始时间、最早页面可交互时间、页面中各种资源的字节数、后端请求
数量等一系列数据；
- 还可以自动给出被测页面性能优化水平的评价指标，告诉我们哪些部分的性能已经做过优化处理了，哪些部分还需要改进；
- 同时，还能提供 Filmstrip 视图、Waterfall 视图、Connection 视图、Request 详情视图和页面加载视频慢动作

WebPagetest 六项前端性能指标的涵义:

- 第一，First Byte Time
    - 指的是用户发起页面请求到接收到服务器返回的第一个字节所花费的时间。这个指标反映了后端服务器处理请求、构建页面，并且通过网络
    返回所花费的时间
- 第二，Keep-alive Enabled
    - 页面上的各种资源（比如，图片、JavaScript、CSS 等）都需要通过链接 Web 服务器来一一获取，与服务器建立新链接的过程往往比较耗费
    时间
        - 所以理想的做法是尽可能重用已经建立好的链接，而避免每次使用都去创建新的链接
    - Keep-alive Enabled 就是，要求每次请求使用已经建立好的链接。它属于服务器上的配置，不需要对页面本身进行任何更改
        - 启用了 Keep-alive 通常可以将加载页面的时间减少 40%~50％，页面的请求数越多，能够节省的时间就越多
- 第三，Compress Transfer
    - 如果将页面上的各种文本类的资源，比如 Html、JavaScript、CSS 等，进行压缩传输，将会减少网络传输的数据量，同时由于 JavaScript
     和 CSS 都是页面上最先被加载的部分，所以减小这部分的数据量会加快页面的加载速度，同时也能缩短 First Byte Time
     - 为文本资源启用压缩通常也是服务器配置更改，无需对页面本身进行任何更改
- 第四，Compress Images
    - 为了减少需要网络传输的数据量，图像文件也需要进行压缩处理
    - 普通 JPEG 文件存储方式是按从上到下的扫描方式，把每一行顺序地保存在 JPEG 文件中。打开这个文件显示它的内容时，数据将按照存储时
    的顺序从上到下一行一行地被显示，直到所有的数据都被读完，就完成了整张图片的显示
        - 如果文件较大或者网络下载速度较慢，就会看到图片是被一行一行加载的。为了更好的用户体验，渐进式 JPEG 技术就出现了
    - 渐进式 JPEG 包含多次扫描，然后将扫描顺序存储在 JPEG 文件中。打开文件的过程，会先显示整个图片的模糊轮廓，随着扫描次数的增加，
    图片会变得越来越清晰
        - 这种格式的主要优点是在网络较慢时，通过图片轮廓就可以知道正在加载的图片大概是什么
- 第五，Cache Static Content
    - 一般情况下，页面上的静态资源不会经常变化，所以如果你的浏览器可以缓存这些资源，那么当重复访问这些页面时，就可以从缓存中直接使
    用已有的副本，而不需要每次向 Web 服务器请求资源
        - 这种做法，可以显著提高重复访问页面的性能，并减少 Web 服务器的负载
- 第六，Effective use of CDN
    - CDN 是内容分发网络的缩写，其基本原理是采用各种缓存服务器，将这些缓存服务器分布到用户访问相对集中的地区的网络供应商机房内
        - 当用户访问网站时，利用全局负载技术将用户的访问指向距离最近的、工作正常的缓存服务器上，由缓存服务器直接响应用户请求

WebPagetest 实际使用中需要解决的问题:

- 第一个问题是，如果被测网站部署在公司内部的网络中，那么处于外网的 WebPagetest 就无法访问这个网站，也就无法完成测试。要解决这个问
题，你需要在公司内网中搭建自己的私有 WebPagetest 以及相关的测试发起机
- 第二个问题是，用 WebPagetest 执行前端测试时，所有的操作都是基于界面操作的，不利于与 CI/CD 的流水线集成。要解决这个问题，就必须
引入 WebPagetest API Wrapper

WebPagetest API Wrapper 是一款基于 Node.js，调用了 WebPagetest 提供的 API 的命令行工具。也就是说，你可以利用这个命令行工具发起
基于 WebPagetest 的前端性能测试，这样就可以很方便地与 CI/CD 流水线集成了。具体的使用步骤如下：

1. 通过 “npm install webpagetest -g” 安装该命令行工具；
2. 访问 https://www.webpagetest.org/getkey.php 获取你的 WebPagetest API Key；
3. 使用 “webpagetest test -k API-KEY 被测页面 URL” 发起测试，该调用是异步操作，会立即返回，并为你提供一个 testId；
4. 使用 “webpagetest status testId” 查询测试是否完成；
5. 测试完成后，就可以通过 “webpagetest results testId” 查看测试报告，但是你会发现测试报告是个很大的 JSON 文件，可读性较差；
6. 通过 “npm install webpagetest-mapper -g” 安装 webpagetest-mapper 工具，这是为了解决测试报告可读性差的问题，将 WebPagetest 
生成的 JSON 文件格式的测试报告转换成为 HTML 文件格式；
7. 使用 “Wptmap -key API-KEY --resultIds testId --output ./test.html” 将 JSON 文件格式的测试结果转换成 HTML 格式

### 无实例无真相：基于LoadRunner实现企业级服务器端性能测试的实践（上）

LoadRunner 的主要模块:

- 第一，Virtual User Generator
    - 用于生成模拟用户行为的测试脚本，生成的手段主要是基于协议的录制，也就是由性能测试脚本开发人员在通过 GUI 执行业务操作的同时，
    录制客户端和服务器之间的通信协议，并最终转化为代码化的 LoadRunner 的虚拟用户脚本
    - 这样转化得到的虚拟脚本往往并不能被直接使用，还需要经历数据参数化（Parameterization）、关联建立（Correlation），以及
    运行时设置（Run Time Settings）等操作，然后才能用于性能测试场景中
- 第二，LoadRunner Controller
    - Controller 相当于性能测试执行的控制管理中心，负责控制 Load Generator 产生测试负载，以执行预先设定好的性能测试场景；同时，
    它还负责收集各类监控数据
    - 在实际执行性能测试时，Controller 是和性能工程师打交道最多的模块，性能工程师会在 Controller 的 UI 界面上完成性能测试场景的
    设计、运行时的实时监控、测试负载的开始与结束等操作
- 第三，LoadRunner Analysis
    - Analysis 是 LoadRunner 中一个强大的分析插件。它不仅能图形化展示测试过程中收集的数据，还能很方便地对多个指标做关联分析，找出
    它们之间的因果关系。它最根本的目的就是，分析出系统可能的性能瓶颈点以及潜在的性能问题
    
从宏观角度来讲，基于 LoadRunner 完成企业级性能测试，可以划分为五个阶段:

1. 性能需求收集以及负载计划制定；
2. 录制并增强虚拟用户脚本；
    - 可以分为识别被测应用使用的协议、录制脚本、完善录制得到的脚本、验证脚本的正确性四步
3. 创建并定义性能测试场景；
4. 执行性能测试场景；
5. 分析测试报告。

### 无实例无真相：基于LoadRunner实现企业级服务器端性能测试的实践（下）

从整体角度来看，用 LoadRunner 开发虚拟用户脚本主要包括以下四个步骤:

1. 识别被测应用使用的协议
2. 录制脚本；
3. 完善录制得到的脚本
4. 验证脚本的正确性

### 站在巨人的肩膀：企业级实际性能测试案例与经验分享

四种测试类型:

- 性能基准测试
    - 通常被称为 Performance Benchmark Test，是每次对外发布产品版本前必须要完成的测试类型
    - 会基于固定的硬件环境和部署架构（比如专用的服务器、固定的专用网络环境、固定大小的集群规模、相同的系统配置、相同的数据库背景
    数据等），通过执行固定的性能测试场景得到系统的性能测试报告，然后与上一版本发布时的指标进行对比，如果发现指标有“恶化”的趋势，
    就需要进一步排查
- 稳定性测试
    - 又称可靠性测试，主要是通过长时间（7*24 小时）模拟被测系统的测试负载，来观察系统在长期运行过程中是否有潜在的问题。通过对系统
    指标的监控，稳定性测试可以发现诸如内存泄漏、资源非法占用等问题
    - 一般是采用“波浪式”的测试负载，比如先逐渐加大测试负载，在高负载情况下持续 10 多个小时，然后再逐渐降低负载，这样就构成了一个
    “波浪”，整个稳定性测试将由很多个这样的波浪连续组成
- 并发测试
    - 是在高并发情况下验证单一业务功能的正确性以及性能的测试手段。高并发测试一般使用思考时间为零的虚拟用户脚本来发起具有 “集合点” 
    的测试
    - 并发测试，往往被当作功能测试的补充，主要用于发现诸如多线程、资源竞争、资源死锁之类的错误。要执行并发测试，就需要加入“集合点”
    ，所以往往需要修改虚拟用户脚本
- 容量规划测试
    - 是为了完成容量规划而设计执行的测试
        - 所谓容量规划，是软件产品为满足用户目标负载而调整自身生产能力的过程
    - 容量规划的主要目的是，解决当系统负载将要达到极限处理能力时，我们应该如何通过垂直扩展（增加单机的硬件资源）和水平扩展（增加
    集群中的机器数量）增加系统整体的负载处理能力的问题

## 测试数据准备篇

### 如何准备测试数据？

从创建测试数据的维度来看，测试数据准备方法主要可以分为四类:

- 基于 GUI 操作生成测试数据；
    - 基于 GUI 操作生成测试数据的方法一般只用于手工测试；注册 登录
- 通过 API 调用生成测试数据；
- 通过数据库操作生成测试数据；
- 综合运用 API 和数据库的方式生成测试数据






### 浅谈测试数据的痛点

### 测试数据的“银弹”- 统一测试数据平台（上）

### 测试数据的“银弹”- 统一测试数据平台（下）



## 测试基础框架篇

### 从小作坊到工厂：什么是Selenium Grid？如何搭建Selenium Grid？

### 从小工到专家：聊聊测试执行环境的架构设计（上）

### 从小工到专家：聊聊测试执行环境的架构设计（下）

### 实战：大型全球化电商的测试基础架构设计




## 测试新技术篇

### 发挥人的潜能：探索式测试

### 测试先行：测试驱动开发(TDD)

### 打蛇打七寸：精准测试

### 安全第一：渗透测试

### 用机器设计测试用例：基于模型的测试





## 测试人员的互联网架构核心知识篇

### 优秀的测试工程师为什么要懂大型网站的架构设计？

### 深入浅出网站高性能架构设计

### 深入浅出网站高可用架构设计

### 深入浅出网站伸缩性架构设计

### 深入浅出网站可扩展性架构设计



## 特别放送篇

### 测试专栏特别放送 | 答疑解惑第一期

### 测试专栏特别放送 | 答疑解惑第二期

### 测试专栏特别放送 | 答疑解惑第三期

### 测试专栏特别放送 | 答疑解惑第四期

### 测试专栏特别放送 | 答疑解惑第五期

### 测试专栏特别放送 | 答疑解惑第六期

### 测试专栏特别放送 | 答疑解惑第七期

### 测试专栏特别放送 | 浅谈全链路压测



## 测一测

### 测一测 | 这些软件测试题目，你都掌握了吗？



## 结束语

### 结束语 | 不是结束，而是开始




